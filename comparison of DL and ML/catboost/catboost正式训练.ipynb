{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "\n",
    "# from catboost_focal_loss import FocalLossObjective\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feat  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \\\n",
      "0         0           1           0           0           0           0   \n",
      "1         0           1           0           0           0           0   \n",
      "2         0           0           0           0           1           0   \n",
      "3         1           0           0           0           0           0   \n",
      "4         0           1           0           0           0           0   \n",
      "...     ...         ...         ...         ...         ...         ...   \n",
      "42063     1           0           0           0           0           0   \n",
      "15693     0           0           1           0           0           0   \n",
      "20174     0           0           0           0           0           1   \n",
      "7824      1           0           0           0           0           0   \n",
      "6986      0           0           1           0           0           0   \n",
      "\n",
      "       Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  ...  Unnamed: 29  \\\n",
      "0               8           0           2         7.00  ...           -4   \n",
      "1               7           0           2         7.00  ...           -2   \n",
      "2               9           1           2        10.53  ...           -2   \n",
      "3               5           0           2         7.00  ...           -2   \n",
      "4               8           0           2         7.00  ...           -4   \n",
      "...           ...         ...         ...          ...  ...          ...   \n",
      "42063           4           0           2         7.00  ...           -4   \n",
      "15693           6           0           4         7.00  ...           -2   \n",
      "20174           8          -1           4         3.65  ...           -6   \n",
      "7824            7           0           2         7.00  ...            0   \n",
      "6986            6           0           4         7.00  ...           -2   \n",
      "\n",
      "       Unnamed: 30  Unnamed: 31  Unnamed: 32  Unnamed: 33  Unnamed: 34  \\\n",
      "0               -1           -2           -4           -4           -2   \n",
      "1               -6            1            6           -4           -3   \n",
      "2               -6            1            6           -4           -3   \n",
      "3               -5           -3           -4            7           -3   \n",
      "4               -1           -2           -4           -4           -2   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "42063           -3           -3           -4           -4            0   \n",
      "15693            0           -1           -2           -1            4   \n",
      "20174           -3           -5           -6           -2            1   \n",
      "7824            -5           -1            0           -5           -4   \n",
      "6986            -2            1           -4           -3            4   \n",
      "\n",
      "       Unnamed: 35  Unnamed: 36  Unnamed: 37  Unnamed: 38  \n",
      "0               -1           -6           -1            0  \n",
      "1               -5            5            7           -3  \n",
      "2               -5            5            7           -3  \n",
      "3               -3            1           -4            2  \n",
      "4               -1           -6           -1            0  \n",
      "...            ...          ...          ...          ...  \n",
      "42063           -1            6           -4           -4  \n",
      "15693            1           -3           -2           -2  \n",
      "20174           -2           -6           -5           -5  \n",
      "7824            -3           -5           -3            5  \n",
      "6986             1           -5           -4           -2  \n",
      "\n",
      "[78650 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./ml.csv\")\n",
    "df_majority = train[train.label==0]\n",
    "df_minority = train[train.label==1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=39325,    # to match majority class\n",
    "                                 random_state=123)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "train_x = df_upsampled.drop('label', axis = 1)     # 删除表中的某一行或者某一列\n",
    "train_y = df_upsampled['label']\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = train_test_split(train_x, train_y, test_size=0.2)\n",
    "train_data, test_data, train_labels, test_labels = Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(train_data, train_labels)\n",
    "test_pool = Pool(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from six.moves import xrange\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "# from catboost_focal_loss import FocalLossObjective\n",
    "params = {\n",
    "    'loss_function' : 'Logloss',\n",
    "    'custom_metric' : ['CrossEntropy', 'Accuracy'],\n",
    "    'iterations' : 4000,        # 最大树数\n",
    "    'learning_rate' : 0.1315,\n",
    "    'l2_leaf_reg': 0.0345,        # L2正则化系数\n",
    "    # 'colsample_bylevel': 0.5,     # 控制树的每一级的每一次分裂，对列数的采样的占比，跟rsm不共存\n",
    "    'depth' : 16,\n",
    "    'boosting_type': 'Plain',\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'rsm' : 0.5927,     #  随机子空间\n",
    "    'min_data_in_leaf': 9,\n",
    "    'random_strength': 13.196,      # 分数标准差乘数\n",
    "    'one_hot_max_size': 9,\n",
    "    'bagging_temperature': 6.6325\n",
    "}\n",
    "#\n",
    "# class FocalLossObjective(object):\n",
    "#     def calc_ders_range(self, approxes, targets, weights):\n",
    "#         # approxes, targets, weights are indexed containers of floats\n",
    "#         # (containers with only __len__ and __getitem__ defined).\n",
    "#         # weights parameter can be None.\n",
    "#         # Returns list of pairs (der1, der2)\n",
    "#         gamma = 2.\n",
    "#         # alpha = 1.\n",
    "#         assert len(approxes) == len(targets)\n",
    "#         if weights is not None:\n",
    "#             assert len(weights) == len(approxes)\n",
    "#\n",
    "#         exponents = []\n",
    "#         for index in xrange(len(approxes)):\n",
    "#             exponents.append(math.exp(approxes[index]))\n",
    "#\n",
    "#         result = []\n",
    "#         for index in xrange(len(targets)):\n",
    "#             p = exponents[index] / (1 + exponents[index])\n",
    "#\n",
    "#             if targets[index] > 0.0:\n",
    "#                 der1 = -((1-p)**(gamma-1))*(gamma * math.log(p) * p + p - 1)/p\n",
    "#                 der2 = gamma*((1-p)**gamma)*((gamma*p-1)*math.log(p)+2*(p-1))\n",
    "#             else:\n",
    "#                 der1 = (p**(gamma-1)) * (gamma * math.log(1 - p) - p)/(1 - p)\n",
    "#                 der2 = p**(gamma-2)*((p*(2*gamma*(p-1)-p))/(p-1)**2 + (gamma-1)*gamma*math.log(1 - p))\n",
    "#\n",
    "#             if weights is not None:\n",
    "#                 der1 *= weights[index]\n",
    "#                 der2 *= weights[index]\n",
    "#\n",
    "#             result.append((der1, der2))\n",
    "#\n",
    "#         return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(**params, early_stopping_rounds=100, eval_metric=\"Logloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3860f6f3a911470e997412e5aac1d1d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6042262\ttest: 0.6257417\tbest: 0.6257417 (0)\ttotal: 964ms\tremaining: 1h 4m 13s\n",
      "1:\tlearn: 0.5239883\ttest: 0.5639610\tbest: 0.5639610 (1)\ttotal: 1.91s\tremaining: 1h 3m 41s\n",
      "2:\tlearn: 0.4627515\ttest: 0.5126662\tbest: 0.5126662 (2)\ttotal: 2.9s\tremaining: 1h 4m 20s\n",
      "3:\tlearn: 0.4310122\ttest: 0.4855437\tbest: 0.4855437 (3)\ttotal: 3.87s\tremaining: 1h 4m 27s\n",
      "4:\tlearn: 0.4045974\ttest: 0.4614312\tbest: 0.4614312 (4)\ttotal: 4.83s\tremaining: 1h 4m 21s\n",
      "5:\tlearn: 0.3617144\ttest: 0.4252492\tbest: 0.4252492 (5)\ttotal: 5.77s\tremaining: 1h 4m 1s\n",
      "6:\tlearn: 0.3353870\ttest: 0.4007025\tbest: 0.4007025 (6)\ttotal: 6.7s\tremaining: 1h 3m 40s\n",
      "7:\tlearn: 0.3220227\ttest: 0.3880659\tbest: 0.3880659 (7)\ttotal: 7.64s\tremaining: 1h 3m 35s\n",
      "8:\tlearn: 0.3009401\ttest: 0.3688628\tbest: 0.3688628 (8)\ttotal: 8.59s\tremaining: 1h 3m 29s\n",
      "9:\tlearn: 0.2890659\ttest: 0.3573695\tbest: 0.3573695 (9)\ttotal: 9.57s\tremaining: 1h 3m 36s\n",
      "10:\tlearn: 0.2804727\ttest: 0.3502889\tbest: 0.3502889 (10)\ttotal: 10.5s\tremaining: 1h 3m 44s\n",
      "11:\tlearn: 0.2641370\ttest: 0.3347963\tbest: 0.3347963 (11)\ttotal: 11.5s\tremaining: 1h 3m 36s\n",
      "12:\tlearn: 0.2513009\ttest: 0.3223583\tbest: 0.3223583 (12)\ttotal: 12.5s\tremaining: 1h 3m 43s\n",
      "13:\tlearn: 0.2424702\ttest: 0.3135674\tbest: 0.3135674 (13)\ttotal: 13.5s\tremaining: 1h 3m 55s\n",
      "14:\tlearn: 0.2350336\ttest: 0.3074991\tbest: 0.3074991 (14)\ttotal: 14.4s\tremaining: 1h 3m 53s\n",
      "15:\tlearn: 0.2278498\ttest: 0.3002904\tbest: 0.3002904 (15)\ttotal: 15.3s\tremaining: 1h 3m 41s\n",
      "16:\tlearn: 0.2148447\ttest: 0.2876065\tbest: 0.2876065 (16)\ttotal: 16.3s\tremaining: 1h 3m 42s\n",
      "17:\tlearn: 0.2097256\ttest: 0.2823707\tbest: 0.2823707 (17)\ttotal: 17.2s\tremaining: 1h 3m 25s\n",
      "18:\tlearn: 0.2065216\ttest: 0.2800601\tbest: 0.2800601 (18)\ttotal: 18.1s\tremaining: 1h 3m 9s\n",
      "19:\tlearn: 0.2039300\ttest: 0.2781227\tbest: 0.2781227 (19)\ttotal: 18.9s\tremaining: 1h 2m 41s\n",
      "20:\tlearn: 0.1968431\ttest: 0.2715268\tbest: 0.2715268 (20)\ttotal: 19.8s\tremaining: 1h 2m 31s\n",
      "21:\tlearn: 0.1918513\ttest: 0.2664324\tbest: 0.2664324 (21)\ttotal: 20.7s\tremaining: 1h 2m 19s\n",
      "22:\tlearn: 0.1853071\ttest: 0.2599043\tbest: 0.2599043 (22)\ttotal: 21.6s\tremaining: 1h 2m 21s\n",
      "23:\tlearn: 0.1818295\ttest: 0.2561722\tbest: 0.2561722 (23)\ttotal: 22.5s\tremaining: 1h 2m 14s\n",
      "24:\tlearn: 0.1722359\ttest: 0.2473148\tbest: 0.2473148 (24)\ttotal: 23.5s\tremaining: 1h 2m 16s\n",
      "25:\tlearn: 0.1687009\ttest: 0.2440562\tbest: 0.2440562 (25)\ttotal: 24.4s\tremaining: 1h 2m 14s\n",
      "26:\tlearn: 0.1642972\ttest: 0.2393333\tbest: 0.2393333 (26)\ttotal: 25.4s\tremaining: 1h 2m 12s\n",
      "27:\tlearn: 0.1596777\ttest: 0.2349968\tbest: 0.2349968 (27)\ttotal: 26.4s\tremaining: 1h 2m 27s\n",
      "28:\tlearn: 0.1557210\ttest: 0.2311379\tbest: 0.2311379 (28)\ttotal: 27.4s\tremaining: 1h 2m 32s\n",
      "29:\tlearn: 0.1519962\ttest: 0.2273888\tbest: 0.2273888 (29)\ttotal: 28.4s\tremaining: 1h 2m 41s\n",
      "30:\tlearn: 0.1472869\ttest: 0.2229593\tbest: 0.2229593 (30)\ttotal: 29.3s\tremaining: 1h 2m 35s\n",
      "31:\tlearn: 0.1434098\ttest: 0.2192613\tbest: 0.2192613 (31)\ttotal: 30.2s\tremaining: 1h 2m 27s\n",
      "32:\tlearn: 0.1414349\ttest: 0.2175563\tbest: 0.2175563 (32)\ttotal: 31s\tremaining: 1h 2m 11s\n",
      "33:\tlearn: 0.1388907\ttest: 0.2155448\tbest: 0.2155448 (33)\ttotal: 31.9s\tremaining: 1h 2m 2s\n",
      "34:\tlearn: 0.1378025\ttest: 0.2145597\tbest: 0.2145597 (34)\ttotal: 32.9s\tremaining: 1h 2m 2s\n",
      "35:\tlearn: 0.1348880\ttest: 0.2119358\tbest: 0.2119358 (35)\ttotal: 33.8s\tremaining: 1h 2m 2s\n",
      "36:\tlearn: 0.1318559\ttest: 0.2089691\tbest: 0.2089691 (36)\ttotal: 34.7s\tremaining: 1h 1m 55s\n",
      "37:\tlearn: 0.1292023\ttest: 0.2065545\tbest: 0.2065545 (37)\ttotal: 35.6s\tremaining: 1h 1m 54s\n",
      "38:\tlearn: 0.1283025\ttest: 0.2062133\tbest: 0.2062133 (38)\ttotal: 36.5s\tremaining: 1h 1m 47s\n",
      "39:\tlearn: 0.1261170\ttest: 0.2040800\tbest: 0.2040800 (39)\ttotal: 37.4s\tremaining: 1h 1m 47s\n",
      "40:\tlearn: 0.1239604\ttest: 0.2019939\tbest: 0.2019939 (40)\ttotal: 38.3s\tremaining: 1h 1m 41s\n",
      "41:\tlearn: 0.1224001\ttest: 0.2007602\tbest: 0.2007602 (41)\ttotal: 39.2s\tremaining: 1h 1m 34s\n",
      "42:\tlearn: 0.1202957\ttest: 0.1986185\tbest: 0.1986185 (42)\ttotal: 40.2s\tremaining: 1h 1m 35s\n",
      "43:\tlearn: 0.1185627\ttest: 0.1970048\tbest: 0.1970048 (43)\ttotal: 41.1s\tremaining: 1h 1m 32s\n",
      "44:\tlearn: 0.1157070\ttest: 0.1937858\tbest: 0.1937858 (44)\ttotal: 42s\tremaining: 1h 1m 32s\n",
      "45:\tlearn: 0.1145796\ttest: 0.1928454\tbest: 0.1928454 (45)\ttotal: 42.9s\tremaining: 1h 1m 28s\n",
      "46:\tlearn: 0.1129755\ttest: 0.1912182\tbest: 0.1912182 (46)\ttotal: 43.9s\tremaining: 1h 1m 28s\n",
      "47:\tlearn: 0.1109168\ttest: 0.1893224\tbest: 0.1893224 (47)\ttotal: 44.8s\tremaining: 1h 1m 26s\n",
      "48:\tlearn: 0.1100011\ttest: 0.1885104\tbest: 0.1885104 (48)\ttotal: 45.7s\tremaining: 1h 1m 21s\n",
      "49:\tlearn: 0.1087353\ttest: 0.1869241\tbest: 0.1869241 (49)\ttotal: 46.5s\tremaining: 1h 1m 13s\n",
      "50:\tlearn: 0.1068469\ttest: 0.1853214\tbest: 0.1853214 (50)\ttotal: 47.4s\tremaining: 1h 1m 6s\n",
      "51:\tlearn: 0.1054125\ttest: 0.1837689\tbest: 0.1837689 (51)\ttotal: 48.2s\tremaining: 1h 1m\n",
      "52:\tlearn: 0.1042362\ttest: 0.1828939\tbest: 0.1828939 (52)\ttotal: 49s\tremaining: 1h 50s\n",
      "53:\tlearn: 0.1026555\ttest: 0.1815386\tbest: 0.1815386 (53)\ttotal: 49.9s\tremaining: 1h 49s\n",
      "54:\tlearn: 0.1017815\ttest: 0.1808961\tbest: 0.1808961 (54)\ttotal: 50.8s\tremaining: 1h 41s\n",
      "55:\tlearn: 0.1004093\ttest: 0.1798650\tbest: 0.1798650 (55)\ttotal: 51.7s\tremaining: 1h 38s\n",
      "56:\tlearn: 0.0982849\ttest: 0.1779456\tbest: 0.1779456 (56)\ttotal: 52.5s\tremaining: 1h 33s\n",
      "57:\tlearn: 0.0977575\ttest: 0.1777626\tbest: 0.1777626 (57)\ttotal: 53.4s\tremaining: 1h 27s\n",
      "58:\tlearn: 0.0966948\ttest: 0.1766698\tbest: 0.1766698 (58)\ttotal: 54.3s\tremaining: 1h 24s\n",
      "59:\tlearn: 0.0955928\ttest: 0.1757923\tbest: 0.1757923 (59)\ttotal: 55.1s\tremaining: 1h 16s\n",
      "60:\tlearn: 0.0946522\ttest: 0.1747395\tbest: 0.1747395 (60)\ttotal: 56s\tremaining: 1h 16s\n",
      "61:\tlearn: 0.0935983\ttest: 0.1741093\tbest: 0.1741093 (61)\ttotal: 56.8s\tremaining: 1h 10s\n",
      "62:\tlearn: 0.0927952\ttest: 0.1732757\tbest: 0.1732757 (62)\ttotal: 57.7s\tremaining: 1h 7s\n",
      "63:\tlearn: 0.0923065\ttest: 0.1727824\tbest: 0.1727824 (63)\ttotal: 58.6s\tremaining: 1h 2s\n",
      "64:\tlearn: 0.0915724\ttest: 0.1721766\tbest: 0.1721766 (64)\ttotal: 59.5s\tremaining: 59m 59s\n",
      "65:\tlearn: 0.0907580\ttest: 0.1715549\tbest: 0.1715549 (65)\ttotal: 1m\tremaining: 59m 56s\n",
      "66:\tlearn: 0.0892321\ttest: 0.1702010\tbest: 0.1702010 (66)\ttotal: 1m 1s\tremaining: 59m 51s\n",
      "67:\tlearn: 0.0878806\ttest: 0.1686187\tbest: 0.1686187 (67)\ttotal: 1m 2s\tremaining: 59m 50s\n",
      "68:\tlearn: 0.0869990\ttest: 0.1679471\tbest: 0.1679471 (68)\ttotal: 1m 2s\tremaining: 59m 45s\n",
      "69:\tlearn: 0.0861167\ttest: 0.1673936\tbest: 0.1673936 (69)\ttotal: 1m 3s\tremaining: 59m 44s\n",
      "70:\tlearn: 0.0856718\ttest: 0.1671093\tbest: 0.1671093 (70)\ttotal: 1m 4s\tremaining: 59m 39s\n",
      "71:\tlearn: 0.0846055\ttest: 0.1659229\tbest: 0.1659229 (71)\ttotal: 1m 5s\tremaining: 59m 37s\n",
      "72:\tlearn: 0.0839077\ttest: 0.1653312\tbest: 0.1653312 (72)\ttotal: 1m 6s\tremaining: 59m 33s\n",
      "73:\tlearn: 0.0833237\ttest: 0.1648933\tbest: 0.1648933 (73)\ttotal: 1m 7s\tremaining: 59m 29s\n",
      "74:\tlearn: 0.0827607\ttest: 0.1643681\tbest: 0.1643681 (74)\ttotal: 1m 8s\tremaining: 59m 27s\n",
      "75:\tlearn: 0.0822949\ttest: 0.1640169\tbest: 0.1640169 (75)\ttotal: 1m 8s\tremaining: 59m 21s\n",
      "76:\tlearn: 0.0813515\ttest: 0.1631022\tbest: 0.1631022 (76)\ttotal: 1m 9s\tremaining: 59m 22s\n",
      "77:\tlearn: 0.0808949\ttest: 0.1627540\tbest: 0.1627540 (77)\ttotal: 1m 10s\tremaining: 59m 18s\n",
      "78:\tlearn: 0.0798812\ttest: 0.1618083\tbest: 0.1618083 (78)\ttotal: 1m 11s\tremaining: 59m 17s\n",
      "79:\tlearn: 0.0796656\ttest: 0.1616274\tbest: 0.1616274 (79)\ttotal: 1m 12s\tremaining: 59m 13s\n",
      "80:\tlearn: 0.0789002\ttest: 0.1607532\tbest: 0.1607532 (80)\ttotal: 1m 13s\tremaining: 59m 12s\n",
      "81:\tlearn: 0.0783418\ttest: 0.1601947\tbest: 0.1601947 (81)\ttotal: 1m 14s\tremaining: 59m 10s\n",
      "82:\tlearn: 0.0777895\ttest: 0.1596311\tbest: 0.1596311 (82)\ttotal: 1m 15s\tremaining: 59m 7s\n",
      "83:\tlearn: 0.0773959\ttest: 0.1592719\tbest: 0.1592719 (83)\ttotal: 1m 16s\tremaining: 59m 6s\n",
      "84:\tlearn: 0.0767888\ttest: 0.1586105\tbest: 0.1586105 (84)\ttotal: 1m 16s\tremaining: 59m 2s\n",
      "85:\tlearn: 0.0757548\ttest: 0.1575232\tbest: 0.1575232 (85)\ttotal: 1m 17s\tremaining: 59m 3s\n",
      "86:\tlearn: 0.0747901\ttest: 0.1563129\tbest: 0.1563129 (86)\ttotal: 1m 18s\tremaining: 59m 2s\n",
      "87:\tlearn: 0.0744056\ttest: 0.1561217\tbest: 0.1561217 (87)\ttotal: 1m 19s\tremaining: 59m 2s\n",
      "88:\tlearn: 0.0738472\ttest: 0.1556472\tbest: 0.1556472 (88)\ttotal: 1m 20s\tremaining: 59m 1s\n",
      "89:\tlearn: 0.0735287\ttest: 0.1554278\tbest: 0.1554278 (89)\ttotal: 1m 21s\tremaining: 59m\n",
      "90:\tlearn: 0.0726401\ttest: 0.1550979\tbest: 0.1550979 (90)\ttotal: 1m 22s\tremaining: 58m 59s\n",
      "91:\tlearn: 0.0721819\ttest: 0.1547325\tbest: 0.1547325 (91)\ttotal: 1m 23s\tremaining: 58m 57s\n",
      "92:\tlearn: 0.0718052\ttest: 0.1546527\tbest: 0.1546527 (92)\ttotal: 1m 24s\tremaining: 58m 57s\n",
      "93:\tlearn: 0.0714478\ttest: 0.1545173\tbest: 0.1545173 (93)\ttotal: 1m 25s\tremaining: 58m 56s\n",
      "94:\tlearn: 0.0710114\ttest: 0.1544140\tbest: 0.1544140 (94)\ttotal: 1m 26s\tremaining: 58m 58s\n",
      "95:\tlearn: 0.0706562\ttest: 0.1540538\tbest: 0.1540538 (95)\ttotal: 1m 26s\tremaining: 58m 55s\n",
      "96:\tlearn: 0.0703289\ttest: 0.1536940\tbest: 0.1536940 (96)\ttotal: 1m 27s\tremaining: 58m 57s\n",
      "97:\tlearn: 0.0700991\ttest: 0.1534902\tbest: 0.1534902 (97)\ttotal: 1m 28s\tremaining: 58m 54s\n",
      "98:\tlearn: 0.0698131\ttest: 0.1531867\tbest: 0.1531867 (98)\ttotal: 1m 29s\tremaining: 58m 54s\n",
      "99:\tlearn: 0.0694329\ttest: 0.1528164\tbest: 0.1528164 (99)\ttotal: 1m 30s\tremaining: 58m 53s\n",
      "100:\tlearn: 0.0691906\ttest: 0.1527264\tbest: 0.1527264 (100)\ttotal: 1m 31s\tremaining: 58m 52s\n",
      "101:\tlearn: 0.0686271\ttest: 0.1521380\tbest: 0.1521380 (101)\ttotal: 1m 32s\tremaining: 58m 52s\n",
      "102:\tlearn: 0.0681700\ttest: 0.1515135\tbest: 0.1515135 (102)\ttotal: 1m 33s\tremaining: 58m 51s\n",
      "103:\tlearn: 0.0679159\ttest: 0.1512634\tbest: 0.1512634 (103)\ttotal: 1m 34s\tremaining: 58m 52s\n",
      "104:\tlearn: 0.0675808\ttest: 0.1509784\tbest: 0.1509784 (104)\ttotal: 1m 35s\tremaining: 58m 51s\n",
      "105:\tlearn: 0.0672413\ttest: 0.1508853\tbest: 0.1508853 (105)\ttotal: 1m 36s\tremaining: 58m 52s\n",
      "106:\tlearn: 0.0670177\ttest: 0.1507734\tbest: 0.1507734 (106)\ttotal: 1m 37s\tremaining: 58m 49s\n",
      "107:\tlearn: 0.0665194\ttest: 0.1505757\tbest: 0.1505757 (107)\ttotal: 1m 37s\tremaining: 58m 51s\n",
      "108:\tlearn: 0.0662452\ttest: 0.1504153\tbest: 0.1504153 (108)\ttotal: 1m 38s\tremaining: 58m 49s\n",
      "109:\tlearn: 0.0658316\ttest: 0.1500283\tbest: 0.1500283 (109)\ttotal: 1m 39s\tremaining: 58m 50s\n",
      "110:\tlearn: 0.0654916\ttest: 0.1498131\tbest: 0.1498131 (110)\ttotal: 1m 40s\tremaining: 58m 49s\n",
      "111:\tlearn: 0.0652892\ttest: 0.1497667\tbest: 0.1497667 (111)\ttotal: 1m 41s\tremaining: 58m 50s\n",
      "112:\tlearn: 0.0649307\ttest: 0.1495616\tbest: 0.1495616 (112)\ttotal: 1m 42s\tremaining: 58m 49s\n",
      "113:\tlearn: 0.0646236\ttest: 0.1494580\tbest: 0.1494580 (113)\ttotal: 1m 43s\tremaining: 58m 50s\n",
      "114:\tlearn: 0.0643818\ttest: 0.1491585\tbest: 0.1491585 (114)\ttotal: 1m 44s\tremaining: 58m 50s\n",
      "115:\tlearn: 0.0639269\ttest: 0.1487148\tbest: 0.1487148 (115)\ttotal: 1m 45s\tremaining: 58m 50s\n",
      "116:\tlearn: 0.0637707\ttest: 0.1486109\tbest: 0.1486109 (116)\ttotal: 1m 46s\tremaining: 58m 51s\n",
      "117:\tlearn: 0.0632927\ttest: 0.1481084\tbest: 0.1481084 (117)\ttotal: 1m 47s\tremaining: 58m 51s\n",
      "118:\tlearn: 0.0630463\ttest: 0.1479884\tbest: 0.1479884 (118)\ttotal: 1m 48s\tremaining: 58m 52s\n",
      "119:\tlearn: 0.0627652\ttest: 0.1479946\tbest: 0.1479884 (118)\ttotal: 1m 49s\tremaining: 58m 52s\n",
      "120:\tlearn: 0.0625709\ttest: 0.1476640\tbest: 0.1476640 (120)\ttotal: 1m 50s\tremaining: 58m 52s\n",
      "121:\tlearn: 0.0624044\ttest: 0.1475485\tbest: 0.1475485 (121)\ttotal: 1m 51s\tremaining: 58m 51s\n",
      "122:\tlearn: 0.0622497\ttest: 0.1475549\tbest: 0.1475485 (121)\ttotal: 1m 52s\tremaining: 58m 53s\n",
      "123:\tlearn: 0.0620647\ttest: 0.1473925\tbest: 0.1473925 (123)\ttotal: 1m 53s\tremaining: 58m 53s\n",
      "124:\tlearn: 0.0619428\ttest: 0.1473886\tbest: 0.1473886 (124)\ttotal: 1m 54s\tremaining: 58m 54s\n",
      "125:\tlearn: 0.0617300\ttest: 0.1471847\tbest: 0.1471847 (125)\ttotal: 1m 54s\tremaining: 58m 53s\n",
      "126:\tlearn: 0.0614454\ttest: 0.1469484\tbest: 0.1469484 (126)\ttotal: 1m 55s\tremaining: 58m 54s\n",
      "127:\tlearn: 0.0610642\ttest: 0.1467390\tbest: 0.1467390 (127)\ttotal: 1m 56s\tremaining: 58m 53s\n",
      "128:\tlearn: 0.0609345\ttest: 0.1466489\tbest: 0.1466489 (128)\ttotal: 1m 57s\tremaining: 58m 54s\n",
      "129:\tlearn: 0.0607479\ttest: 0.1465741\tbest: 0.1465741 (129)\ttotal: 1m 58s\tremaining: 58m 54s\n",
      "130:\tlearn: 0.0606147\ttest: 0.1465959\tbest: 0.1465741 (129)\ttotal: 1m 59s\tremaining: 58m 54s\n",
      "131:\tlearn: 0.0603789\ttest: 0.1464152\tbest: 0.1464152 (131)\ttotal: 2m\tremaining: 58m 54s\n",
      "132:\tlearn: 0.0602857\ttest: 0.1463197\tbest: 0.1463197 (132)\ttotal: 2m 1s\tremaining: 58m 54s\n",
      "133:\tlearn: 0.0600594\ttest: 0.1460405\tbest: 0.1460405 (133)\ttotal: 2m 2s\tremaining: 58m 54s\n",
      "134:\tlearn: 0.0599861\ttest: 0.1460709\tbest: 0.1460405 (133)\ttotal: 2m 3s\tremaining: 58m 54s\n",
      "135:\tlearn: 0.0598118\ttest: 0.1460975\tbest: 0.1460405 (133)\ttotal: 2m 4s\tremaining: 58m 55s\n",
      "136:\tlearn: 0.0595950\ttest: 0.1457321\tbest: 0.1457321 (136)\ttotal: 2m 5s\tremaining: 58m 55s\n",
      "137:\tlearn: 0.0594250\ttest: 0.1456526\tbest: 0.1456526 (137)\ttotal: 2m 6s\tremaining: 58m 55s\n",
      "138:\tlearn: 0.0592646\ttest: 0.1453108\tbest: 0.1453108 (138)\ttotal: 2m 7s\tremaining: 58m 55s\n",
      "139:\tlearn: 0.0591651\ttest: 0.1453027\tbest: 0.1453027 (139)\ttotal: 2m 8s\tremaining: 58m 56s\n",
      "140:\tlearn: 0.0588726\ttest: 0.1450126\tbest: 0.1450126 (140)\ttotal: 2m 9s\tremaining: 58m 56s\n",
      "141:\tlearn: 0.0585418\ttest: 0.1446834\tbest: 0.1446834 (141)\ttotal: 2m 10s\tremaining: 58m 57s\n",
      "142:\tlearn: 0.0583456\ttest: 0.1444372\tbest: 0.1444372 (142)\ttotal: 2m 11s\tremaining: 58m 56s\n",
      "143:\tlearn: 0.0581213\ttest: 0.1444069\tbest: 0.1444069 (143)\ttotal: 2m 12s\tremaining: 58m 58s\n",
      "144:\tlearn: 0.0579985\ttest: 0.1443609\tbest: 0.1443609 (144)\ttotal: 2m 13s\tremaining: 58m 57s\n",
      "145:\tlearn: 0.0578153\ttest: 0.1444762\tbest: 0.1443609 (144)\ttotal: 2m 14s\tremaining: 58m 57s\n",
      "146:\tlearn: 0.0576433\ttest: 0.1442989\tbest: 0.1442989 (146)\ttotal: 2m 14s\tremaining: 58m 57s\n",
      "147:\tlearn: 0.0573952\ttest: 0.1441210\tbest: 0.1441210 (147)\ttotal: 2m 15s\tremaining: 58m 56s\n",
      "148:\tlearn: 0.0572582\ttest: 0.1440772\tbest: 0.1440772 (148)\ttotal: 2m 16s\tremaining: 58m 57s\n",
      "149:\tlearn: 0.0570307\ttest: 0.1438240\tbest: 0.1438240 (149)\ttotal: 2m 17s\tremaining: 58m 57s\n",
      "150:\tlearn: 0.0569056\ttest: 0.1437667\tbest: 0.1437667 (150)\ttotal: 2m 18s\tremaining: 58m 57s\n",
      "151:\tlearn: 0.0567367\ttest: 0.1436819\tbest: 0.1436819 (151)\ttotal: 2m 19s\tremaining: 58m 57s\n",
      "152:\tlearn: 0.0565738\ttest: 0.1433277\tbest: 0.1433277 (152)\ttotal: 2m 20s\tremaining: 58m 58s\n",
      "153:\tlearn: 0.0564908\ttest: 0.1434095\tbest: 0.1433277 (152)\ttotal: 2m 21s\tremaining: 58m 59s\n",
      "154:\tlearn: 0.0563964\ttest: 0.1432748\tbest: 0.1432748 (154)\ttotal: 2m 22s\tremaining: 58m 59s\n",
      "155:\tlearn: 0.0562945\ttest: 0.1432831\tbest: 0.1432748 (154)\ttotal: 2m 23s\tremaining: 58m 59s\n",
      "156:\tlearn: 0.0561819\ttest: 0.1432679\tbest: 0.1432679 (156)\ttotal: 2m 24s\tremaining: 58m 59s\n",
      "157:\tlearn: 0.0560524\ttest: 0.1432078\tbest: 0.1432078 (157)\ttotal: 2m 25s\tremaining: 59m\n",
      "158:\tlearn: 0.0559727\ttest: 0.1431016\tbest: 0.1431016 (158)\ttotal: 2m 26s\tremaining: 59m\n",
      "159:\tlearn: 0.0557619\ttest: 0.1429227\tbest: 0.1429227 (159)\ttotal: 2m 27s\tremaining: 59m\n",
      "160:\tlearn: 0.0555774\ttest: 0.1428005\tbest: 0.1428005 (160)\ttotal: 2m 28s\tremaining: 59m 1s\n",
      "161:\tlearn: 0.0554542\ttest: 0.1427365\tbest: 0.1427365 (161)\ttotal: 2m 29s\tremaining: 59m\n",
      "162:\tlearn: 0.0553547\ttest: 0.1428602\tbest: 0.1427365 (161)\ttotal: 2m 30s\tremaining: 59m 1s\n",
      "163:\tlearn: 0.0552511\ttest: 0.1426799\tbest: 0.1426799 (163)\ttotal: 2m 31s\tremaining: 59m\n",
      "164:\tlearn: 0.0551878\ttest: 0.1427427\tbest: 0.1426799 (163)\ttotal: 2m 32s\tremaining: 59m\n",
      "165:\tlearn: 0.0550699\ttest: 0.1427298\tbest: 0.1426799 (163)\ttotal: 2m 33s\tremaining: 59m 1s\n",
      "166:\tlearn: 0.0550062\ttest: 0.1427703\tbest: 0.1426799 (163)\ttotal: 2m 34s\tremaining: 59m 1s\n",
      "167:\tlearn: 0.0548844\ttest: 0.1428834\tbest: 0.1426799 (163)\ttotal: 2m 35s\tremaining: 59m 1s\n",
      "168:\tlearn: 0.0548267\ttest: 0.1428250\tbest: 0.1426799 (163)\ttotal: 2m 36s\tremaining: 59m 1s\n",
      "169:\tlearn: 0.0546306\ttest: 0.1426693\tbest: 0.1426693 (169)\ttotal: 2m 37s\tremaining: 59m 2s\n",
      "170:\tlearn: 0.0545588\ttest: 0.1426490\tbest: 0.1426490 (170)\ttotal: 2m 38s\tremaining: 59m 1s\n",
      "171:\tlearn: 0.0543625\ttest: 0.1426643\tbest: 0.1426490 (170)\ttotal: 2m 39s\tremaining: 59m 2s\n",
      "172:\tlearn: 0.0542605\ttest: 0.1427468\tbest: 0.1426490 (170)\ttotal: 2m 40s\tremaining: 59m 1s\n",
      "173:\tlearn: 0.0540786\ttest: 0.1427019\tbest: 0.1426490 (170)\ttotal: 2m 41s\tremaining: 59m 2s\n",
      "174:\tlearn: 0.0540341\ttest: 0.1426339\tbest: 0.1426339 (174)\ttotal: 2m 42s\tremaining: 59m 1s\n",
      "175:\tlearn: 0.0539518\ttest: 0.1427570\tbest: 0.1426339 (174)\ttotal: 2m 43s\tremaining: 59m 2s\n",
      "176:\tlearn: 0.0538508\ttest: 0.1426766\tbest: 0.1426339 (174)\ttotal: 2m 43s\tremaining: 59m 1s\n",
      "177:\tlearn: 0.0537579\ttest: 0.1426053\tbest: 0.1426053 (177)\ttotal: 2m 44s\tremaining: 59m 2s\n",
      "178:\tlearn: 0.0536692\ttest: 0.1425752\tbest: 0.1425752 (178)\ttotal: 2m 45s\tremaining: 59m 1s\n",
      "179:\tlearn: 0.0535362\ttest: 0.1424338\tbest: 0.1424338 (179)\ttotal: 2m 46s\tremaining: 59m 2s\n",
      "180:\tlearn: 0.0534051\ttest: 0.1423987\tbest: 0.1423987 (180)\ttotal: 2m 47s\tremaining: 59m 2s\n",
      "181:\tlearn: 0.0533504\ttest: 0.1424158\tbest: 0.1423987 (180)\ttotal: 2m 48s\tremaining: 59m 1s\n",
      "182:\tlearn: 0.0532673\ttest: 0.1424409\tbest: 0.1423987 (180)\ttotal: 2m 49s\tremaining: 59m 1s\n",
      "183:\tlearn: 0.0529759\ttest: 0.1421214\tbest: 0.1421214 (183)\ttotal: 2m 50s\tremaining: 59m 1s\n",
      "184:\tlearn: 0.0528194\ttest: 0.1419333\tbest: 0.1419333 (184)\ttotal: 2m 51s\tremaining: 59m 1s\n",
      "185:\tlearn: 0.0527175\ttest: 0.1420152\tbest: 0.1419333 (184)\ttotal: 2m 52s\tremaining: 59m\n",
      "186:\tlearn: 0.0525989\ttest: 0.1420386\tbest: 0.1419333 (184)\ttotal: 2m 53s\tremaining: 59m\n",
      "187:\tlearn: 0.0524853\ttest: 0.1419375\tbest: 0.1419333 (184)\ttotal: 2m 54s\tremaining: 59m\n",
      "188:\tlearn: 0.0523644\ttest: 0.1418881\tbest: 0.1418881 (188)\ttotal: 2m 55s\tremaining: 58m 59s\n",
      "189:\tlearn: 0.0522986\ttest: 0.1417946\tbest: 0.1417946 (189)\ttotal: 2m 56s\tremaining: 58m 59s\n",
      "190:\tlearn: 0.0522254\ttest: 0.1418102\tbest: 0.1417946 (189)\ttotal: 2m 57s\tremaining: 58m 59s\n",
      "191:\tlearn: 0.0521085\ttest: 0.1417747\tbest: 0.1417747 (191)\ttotal: 2m 58s\tremaining: 58m 59s\n",
      "192:\tlearn: 0.0520175\ttest: 0.1417632\tbest: 0.1417632 (192)\ttotal: 2m 59s\tremaining: 58m 59s\n",
      "193:\tlearn: 0.0518608\ttest: 0.1418680\tbest: 0.1417632 (192)\ttotal: 3m\tremaining: 58m 59s\n",
      "194:\tlearn: 0.0517872\ttest: 0.1418891\tbest: 0.1417632 (192)\ttotal: 3m 1s\tremaining: 58m 58s\n",
      "195:\tlearn: 0.0517308\ttest: 0.1420121\tbest: 0.1417632 (192)\ttotal: 3m 2s\tremaining: 58m 58s\n",
      "196:\tlearn: 0.0516940\ttest: 0.1420158\tbest: 0.1417632 (192)\ttotal: 3m 3s\tremaining: 58m 58s\n",
      "197:\tlearn: 0.0515923\ttest: 0.1418896\tbest: 0.1417632 (192)\ttotal: 3m 4s\tremaining: 58m 58s\n",
      "198:\tlearn: 0.0514373\ttest: 0.1418598\tbest: 0.1417632 (192)\ttotal: 3m 5s\tremaining: 58m 58s\n",
      "199:\tlearn: 0.0513111\ttest: 0.1418986\tbest: 0.1417632 (192)\ttotal: 3m 6s\tremaining: 58m 58s\n",
      "200:\tlearn: 0.0512496\ttest: 0.1418692\tbest: 0.1417632 (192)\ttotal: 3m 7s\tremaining: 58m 58s\n",
      "201:\tlearn: 0.0511860\ttest: 0.1417248\tbest: 0.1417248 (201)\ttotal: 3m 8s\tremaining: 58m 58s\n",
      "202:\tlearn: 0.0510241\ttest: 0.1416513\tbest: 0.1416513 (202)\ttotal: 3m 9s\tremaining: 58m 58s\n",
      "203:\tlearn: 0.0509759\ttest: 0.1417185\tbest: 0.1416513 (202)\ttotal: 3m 10s\tremaining: 58m 58s\n",
      "204:\tlearn: 0.0509343\ttest: 0.1418371\tbest: 0.1416513 (202)\ttotal: 3m 11s\tremaining: 58m 58s\n",
      "205:\tlearn: 0.0508138\ttest: 0.1417222\tbest: 0.1416513 (202)\ttotal: 3m 12s\tremaining: 58m 58s\n",
      "206:\tlearn: 0.0507398\ttest: 0.1416410\tbest: 0.1416410 (206)\ttotal: 3m 13s\tremaining: 58m 57s\n",
      "207:\tlearn: 0.0506554\ttest: 0.1416741\tbest: 0.1416410 (206)\ttotal: 3m 14s\tremaining: 58m 57s\n",
      "208:\tlearn: 0.0506152\ttest: 0.1416495\tbest: 0.1416410 (206)\ttotal: 3m 14s\tremaining: 58m 56s\n",
      "209:\tlearn: 0.0504482\ttest: 0.1414957\tbest: 0.1414957 (209)\ttotal: 3m 15s\tremaining: 58m 56s\n",
      "210:\tlearn: 0.0504133\ttest: 0.1415127\tbest: 0.1414957 (209)\ttotal: 3m 16s\tremaining: 58m 56s\n",
      "211:\tlearn: 0.0503444\ttest: 0.1414633\tbest: 0.1414633 (211)\ttotal: 3m 17s\tremaining: 58m 56s\n",
      "212:\tlearn: 0.0503166\ttest: 0.1415196\tbest: 0.1414633 (211)\ttotal: 3m 18s\tremaining: 58m 56s\n",
      "213:\tlearn: 0.0502660\ttest: 0.1414230\tbest: 0.1414230 (213)\ttotal: 3m 19s\tremaining: 58m 56s\n",
      "214:\tlearn: 0.0502277\ttest: 0.1413754\tbest: 0.1413754 (214)\ttotal: 3m 20s\tremaining: 58m 55s\n",
      "215:\tlearn: 0.0501354\ttest: 0.1413381\tbest: 0.1413381 (215)\ttotal: 3m 21s\tremaining: 58m 55s\n",
      "216:\tlearn: 0.0500804\ttest: 0.1411951\tbest: 0.1411951 (216)\ttotal: 3m 22s\tremaining: 58m 56s\n",
      "217:\tlearn: 0.0499949\ttest: 0.1409667\tbest: 0.1409667 (217)\ttotal: 3m 23s\tremaining: 58m 55s\n",
      "218:\tlearn: 0.0499433\ttest: 0.1409924\tbest: 0.1409667 (217)\ttotal: 3m 24s\tremaining: 58m 55s\n",
      "219:\tlearn: 0.0497679\ttest: 0.1407898\tbest: 0.1407898 (219)\ttotal: 3m 25s\tremaining: 58m 55s\n",
      "220:\tlearn: 0.0496957\ttest: 0.1408603\tbest: 0.1407898 (219)\ttotal: 3m 26s\tremaining: 58m 55s\n",
      "221:\tlearn: 0.0496239\ttest: 0.1409693\tbest: 0.1407898 (219)\ttotal: 3m 27s\tremaining: 58m 54s\n",
      "222:\tlearn: 0.0495832\ttest: 0.1410348\tbest: 0.1407898 (219)\ttotal: 3m 28s\tremaining: 58m 53s\n",
      "223:\tlearn: 0.0495007\ttest: 0.1411227\tbest: 0.1407898 (219)\ttotal: 3m 29s\tremaining: 58m 53s\n",
      "224:\tlearn: 0.0494022\ttest: 0.1410209\tbest: 0.1407898 (219)\ttotal: 3m 30s\tremaining: 58m 53s\n",
      "225:\tlearn: 0.0493560\ttest: 0.1409868\tbest: 0.1407898 (219)\ttotal: 3m 31s\tremaining: 58m 53s\n",
      "226:\tlearn: 0.0493023\ttest: 0.1410657\tbest: 0.1407898 (219)\ttotal: 3m 32s\tremaining: 58m 52s\n",
      "227:\tlearn: 0.0492435\ttest: 0.1411384\tbest: 0.1407898 (219)\ttotal: 3m 33s\tremaining: 58m 52s\n",
      "228:\tlearn: 0.0491704\ttest: 0.1411417\tbest: 0.1407898 (219)\ttotal: 3m 34s\tremaining: 58m 51s\n",
      "229:\tlearn: 0.0489943\ttest: 0.1409660\tbest: 0.1407898 (219)\ttotal: 3m 35s\tremaining: 58m 51s\n",
      "230:\tlearn: 0.0489757\ttest: 0.1409302\tbest: 0.1407898 (219)\ttotal: 3m 36s\tremaining: 58m 50s\n",
      "231:\tlearn: 0.0489095\ttest: 0.1408946\tbest: 0.1407898 (219)\ttotal: 3m 37s\tremaining: 58m 50s\n",
      "232:\tlearn: 0.0488117\ttest: 0.1408576\tbest: 0.1407898 (219)\ttotal: 3m 38s\tremaining: 58m 49s\n",
      "233:\tlearn: 0.0487941\ttest: 0.1408600\tbest: 0.1407898 (219)\ttotal: 3m 39s\tremaining: 58m 49s\n",
      "234:\tlearn: 0.0487295\ttest: 0.1409737\tbest: 0.1407898 (219)\ttotal: 3m 40s\tremaining: 58m 48s\n",
      "235:\tlearn: 0.0486788\ttest: 0.1410084\tbest: 0.1407898 (219)\ttotal: 3m 41s\tremaining: 58m 48s\n",
      "236:\tlearn: 0.0486247\ttest: 0.1410129\tbest: 0.1407898 (219)\ttotal: 3m 42s\tremaining: 58m 47s\n",
      "237:\tlearn: 0.0485857\ttest: 0.1410457\tbest: 0.1407898 (219)\ttotal: 3m 43s\tremaining: 58m 48s\n",
      "238:\tlearn: 0.0485291\ttest: 0.1411762\tbest: 0.1407898 (219)\ttotal: 3m 44s\tremaining: 58m 47s\n",
      "239:\tlearn: 0.0484744\ttest: 0.1411301\tbest: 0.1407898 (219)\ttotal: 3m 45s\tremaining: 58m 47s\n",
      "240:\tlearn: 0.0483618\ttest: 0.1409768\tbest: 0.1407898 (219)\ttotal: 3m 46s\tremaining: 58m 47s\n",
      "241:\tlearn: 0.0482892\ttest: 0.1410590\tbest: 0.1407898 (219)\ttotal: 3m 47s\tremaining: 58m 47s\n",
      "242:\tlearn: 0.0481095\ttest: 0.1409572\tbest: 0.1407898 (219)\ttotal: 3m 48s\tremaining: 58m 47s\n",
      "243:\tlearn: 0.0480837\ttest: 0.1410358\tbest: 0.1407898 (219)\ttotal: 3m 49s\tremaining: 58m 47s\n",
      "244:\tlearn: 0.0479970\ttest: 0.1409740\tbest: 0.1407898 (219)\ttotal: 3m 50s\tremaining: 58m 46s\n",
      "245:\tlearn: 0.0479656\ttest: 0.1408838\tbest: 0.1407898 (219)\ttotal: 3m 51s\tremaining: 58m 46s\n",
      "246:\tlearn: 0.0479119\ttest: 0.1409579\tbest: 0.1407898 (219)\ttotal: 3m 52s\tremaining: 58m 45s\n",
      "247:\tlearn: 0.0478698\ttest: 0.1410013\tbest: 0.1407898 (219)\ttotal: 3m 53s\tremaining: 58m 45s\n",
      "248:\tlearn: 0.0478481\ttest: 0.1410689\tbest: 0.1407898 (219)\ttotal: 3m 53s\tremaining: 58m 44s\n",
      "249:\tlearn: 0.0478275\ttest: 0.1411280\tbest: 0.1407898 (219)\ttotal: 3m 54s\tremaining: 58m 44s\n",
      "250:\tlearn: 0.0477454\ttest: 0.1411131\tbest: 0.1407898 (219)\ttotal: 3m 55s\tremaining: 58m 43s\n",
      "251:\tlearn: 0.0477028\ttest: 0.1410411\tbest: 0.1407898 (219)\ttotal: 3m 56s\tremaining: 58m 43s\n",
      "252:\tlearn: 0.0476704\ttest: 0.1410684\tbest: 0.1407898 (219)\ttotal: 3m 57s\tremaining: 58m 42s\n",
      "253:\tlearn: 0.0476449\ttest: 0.1411298\tbest: 0.1407898 (219)\ttotal: 3m 58s\tremaining: 58m 42s\n",
      "254:\tlearn: 0.0476128\ttest: 0.1412274\tbest: 0.1407898 (219)\ttotal: 3m 59s\tremaining: 58m 41s\n",
      "255:\tlearn: 0.0475127\ttest: 0.1411482\tbest: 0.1407898 (219)\ttotal: 4m\tremaining: 58m 41s\n",
      "256:\tlearn: 0.0474857\ttest: 0.1411912\tbest: 0.1407898 (219)\ttotal: 4m 1s\tremaining: 58m 40s\n",
      "257:\tlearn: 0.0474605\ttest: 0.1412843\tbest: 0.1407898 (219)\ttotal: 4m 2s\tremaining: 58m 40s\n",
      "258:\tlearn: 0.0474157\ttest: 0.1412312\tbest: 0.1407898 (219)\ttotal: 4m 3s\tremaining: 58m 39s\n",
      "259:\tlearn: 0.0473568\ttest: 0.1411267\tbest: 0.1407898 (219)\ttotal: 4m 4s\tremaining: 58m 39s\n",
      "260:\tlearn: 0.0473100\ttest: 0.1413175\tbest: 0.1407898 (219)\ttotal: 4m 5s\tremaining: 58m 38s\n",
      "261:\tlearn: 0.0472814\ttest: 0.1413500\tbest: 0.1407898 (219)\ttotal: 4m 6s\tremaining: 58m 37s\n",
      "262:\tlearn: 0.0472167\ttest: 0.1413452\tbest: 0.1407898 (219)\ttotal: 4m 7s\tremaining: 58m 37s\n",
      "263:\tlearn: 0.0471560\ttest: 0.1412932\tbest: 0.1407898 (219)\ttotal: 4m 8s\tremaining: 58m 36s\n",
      "264:\tlearn: 0.0471243\ttest: 0.1413294\tbest: 0.1407898 (219)\ttotal: 4m 9s\tremaining: 58m 36s\n",
      "265:\tlearn: 0.0470328\ttest: 0.1413604\tbest: 0.1407898 (219)\ttotal: 4m 10s\tremaining: 58m 35s\n",
      "266:\tlearn: 0.0469710\ttest: 0.1412212\tbest: 0.1407898 (219)\ttotal: 4m 11s\tremaining: 58m 34s\n",
      "267:\tlearn: 0.0469274\ttest: 0.1412621\tbest: 0.1407898 (219)\ttotal: 4m 12s\tremaining: 58m 34s\n",
      "268:\tlearn: 0.0468715\ttest: 0.1411301\tbest: 0.1407898 (219)\ttotal: 4m 13s\tremaining: 58m 33s\n",
      "269:\tlearn: 0.0468003\ttest: 0.1411628\tbest: 0.1407898 (219)\ttotal: 4m 14s\tremaining: 58m 32s\n",
      "270:\tlearn: 0.0467395\ttest: 0.1411084\tbest: 0.1407898 (219)\ttotal: 4m 15s\tremaining: 58m 32s\n",
      "271:\tlearn: 0.0467045\ttest: 0.1411922\tbest: 0.1407898 (219)\ttotal: 4m 16s\tremaining: 58m 31s\n",
      "272:\tlearn: 0.0465632\ttest: 0.1411812\tbest: 0.1407898 (219)\ttotal: 4m 17s\tremaining: 58m 31s\n",
      "273:\tlearn: 0.0465102\ttest: 0.1411720\tbest: 0.1407898 (219)\ttotal: 4m 18s\tremaining: 58m 31s\n",
      "274:\tlearn: 0.0464852\ttest: 0.1412563\tbest: 0.1407898 (219)\ttotal: 4m 19s\tremaining: 58m 30s\n",
      "275:\tlearn: 0.0464230\ttest: 0.1412200\tbest: 0.1407898 (219)\ttotal: 4m 20s\tremaining: 58m 29s\n",
      "276:\tlearn: 0.0463827\ttest: 0.1411732\tbest: 0.1407898 (219)\ttotal: 4m 21s\tremaining: 58m 29s\n",
      "277:\tlearn: 0.0463380\ttest: 0.1412872\tbest: 0.1407898 (219)\ttotal: 4m 22s\tremaining: 58m 28s\n",
      "278:\tlearn: 0.0463004\ttest: 0.1413031\tbest: 0.1407898 (219)\ttotal: 4m 23s\tremaining: 58m 27s\n",
      "279:\tlearn: 0.0462775\ttest: 0.1413310\tbest: 0.1407898 (219)\ttotal: 4m 23s\tremaining: 58m 27s\n",
      "280:\tlearn: 0.0462429\ttest: 0.1413138\tbest: 0.1407898 (219)\ttotal: 4m 24s\tremaining: 58m 26s\n",
      "281:\tlearn: 0.0461937\ttest: 0.1412672\tbest: 0.1407898 (219)\ttotal: 4m 25s\tremaining: 58m 25s\n",
      "282:\tlearn: 0.0461453\ttest: 0.1412312\tbest: 0.1407898 (219)\ttotal: 4m 26s\tremaining: 58m 25s\n",
      "283:\tlearn: 0.0461347\ttest: 0.1412098\tbest: 0.1407898 (219)\ttotal: 4m 27s\tremaining: 58m 24s\n",
      "284:\tlearn: 0.0461122\ttest: 0.1411671\tbest: 0.1407898 (219)\ttotal: 4m 28s\tremaining: 58m 24s\n",
      "285:\tlearn: 0.0460700\ttest: 0.1412175\tbest: 0.1407898 (219)\ttotal: 4m 29s\tremaining: 58m 23s\n",
      "286:\tlearn: 0.0460139\ttest: 0.1412608\tbest: 0.1407898 (219)\ttotal: 4m 30s\tremaining: 58m 22s\n",
      "287:\tlearn: 0.0459956\ttest: 0.1412760\tbest: 0.1407898 (219)\ttotal: 4m 31s\tremaining: 58m 21s\n",
      "288:\tlearn: 0.0459615\ttest: 0.1412795\tbest: 0.1407898 (219)\ttotal: 4m 32s\tremaining: 58m 21s\n",
      "289:\tlearn: 0.0459088\ttest: 0.1413109\tbest: 0.1407898 (219)\ttotal: 4m 33s\tremaining: 58m 20s\n",
      "290:\tlearn: 0.0458799\ttest: 0.1413159\tbest: 0.1407898 (219)\ttotal: 4m 34s\tremaining: 58m 19s\n",
      "291:\tlearn: 0.0458110\ttest: 0.1411860\tbest: 0.1407898 (219)\ttotal: 4m 35s\tremaining: 58m 18s\n",
      "292:\tlearn: 0.0457729\ttest: 0.1412325\tbest: 0.1407898 (219)\ttotal: 4m 36s\tremaining: 58m 18s\n",
      "293:\tlearn: 0.0457609\ttest: 0.1411682\tbest: 0.1407898 (219)\ttotal: 4m 37s\tremaining: 58m 17s\n",
      "294:\tlearn: 0.0457217\ttest: 0.1411561\tbest: 0.1407898 (219)\ttotal: 4m 38s\tremaining: 58m 16s\n",
      "295:\tlearn: 0.0457040\ttest: 0.1411603\tbest: 0.1407898 (219)\ttotal: 4m 39s\tremaining: 58m 16s\n",
      "296:\tlearn: 0.0456620\ttest: 0.1412148\tbest: 0.1407898 (219)\ttotal: 4m 40s\tremaining: 58m 15s\n",
      "297:\tlearn: 0.0456193\ttest: 0.1412699\tbest: 0.1407898 (219)\ttotal: 4m 41s\tremaining: 58m 16s\n",
      "298:\tlearn: 0.0455866\ttest: 0.1412989\tbest: 0.1407898 (219)\ttotal: 4m 42s\tremaining: 58m 15s\n",
      "299:\tlearn: 0.0455491\ttest: 0.1413014\tbest: 0.1407898 (219)\ttotal: 4m 43s\tremaining: 58m 14s\n",
      "300:\tlearn: 0.0455194\ttest: 0.1413169\tbest: 0.1407898 (219)\ttotal: 4m 44s\tremaining: 58m 14s\n",
      "301:\tlearn: 0.0455047\ttest: 0.1413639\tbest: 0.1407898 (219)\ttotal: 4m 45s\tremaining: 58m 13s\n",
      "302:\tlearn: 0.0454532\ttest: 0.1414883\tbest: 0.1407898 (219)\ttotal: 4m 46s\tremaining: 58m 12s\n",
      "303:\tlearn: 0.0454423\ttest: 0.1414455\tbest: 0.1407898 (219)\ttotal: 4m 47s\tremaining: 58m 12s\n",
      "304:\tlearn: 0.0454221\ttest: 0.1415031\tbest: 0.1407898 (219)\ttotal: 4m 48s\tremaining: 58m 11s\n",
      "305:\tlearn: 0.0454038\ttest: 0.1414960\tbest: 0.1407898 (219)\ttotal: 4m 49s\tremaining: 58m 11s\n",
      "306:\tlearn: 0.0453920\ttest: 0.1415322\tbest: 0.1407898 (219)\ttotal: 4m 50s\tremaining: 58m 9s\n",
      "307:\tlearn: 0.0453647\ttest: 0.1416044\tbest: 0.1407898 (219)\ttotal: 4m 51s\tremaining: 58m 10s\n",
      "308:\tlearn: 0.0453318\ttest: 0.1415285\tbest: 0.1407898 (219)\ttotal: 4m 52s\tremaining: 58m 9s\n",
      "309:\tlearn: 0.0452935\ttest: 0.1416021\tbest: 0.1407898 (219)\ttotal: 4m 53s\tremaining: 58m 9s\n",
      "310:\tlearn: 0.0452720\ttest: 0.1416635\tbest: 0.1407898 (219)\ttotal: 4m 54s\tremaining: 58m 8s\n",
      "311:\tlearn: 0.0452636\ttest: 0.1415993\tbest: 0.1407898 (219)\ttotal: 4m 55s\tremaining: 58m 8s\n",
      "312:\tlearn: 0.0452384\ttest: 0.1415958\tbest: 0.1407898 (219)\ttotal: 4m 56s\tremaining: 58m 8s\n",
      "313:\tlearn: 0.0451978\ttest: 0.1416356\tbest: 0.1407898 (219)\ttotal: 4m 57s\tremaining: 58m 8s\n",
      "314:\tlearn: 0.0451823\ttest: 0.1416258\tbest: 0.1407898 (219)\ttotal: 4m 58s\tremaining: 58m 7s\n",
      "315:\tlearn: 0.0451672\ttest: 0.1417107\tbest: 0.1407898 (219)\ttotal: 4m 59s\tremaining: 58m 7s\n",
      "316:\tlearn: 0.0451381\ttest: 0.1416333\tbest: 0.1407898 (219)\ttotal: 5m\tremaining: 58m 7s\n",
      "317:\tlearn: 0.0451074\ttest: 0.1416985\tbest: 0.1407898 (219)\ttotal: 5m 1s\tremaining: 58m 6s\n",
      "318:\tlearn: 0.0450703\ttest: 0.1416733\tbest: 0.1407898 (219)\ttotal: 5m 2s\tremaining: 58m 6s\n",
      "319:\tlearn: 0.0450436\ttest: 0.1416706\tbest: 0.1407898 (219)\ttotal: 5m 3s\tremaining: 58m 5s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.1407898346\n",
      "bestIteration = 219\n",
      "\n",
      "Shrink model to first 220 iterations.\n",
      "AUC→ 0.954726146981797\n",
      "ACC→ 0.9546726001271456\n",
      "F1 score→ 0.9558322492721303\n",
      "precision→ 0.9303026648981069\n",
      "recall→ 0.9828025477707006\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_pool, plot=True, eval_set=test_pool)\n",
    "preds_raw = clf.predict(test_data,\n",
    "                            prediction_type='RawFormulaVal')\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "y_pred = clf.predict(test_data)\n",
    "print('AUC→',roc_auc_score(test_labels, y_pred))\n",
    "print('ACC→',accuracy_score(test_labels, y_pred))\n",
    "print('F1 score→',f1_score(test_labels, y_pred))\n",
    "print('precision→',precision_score(test_labels, y_pred))\n",
    "print('recall→',recall_score(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}